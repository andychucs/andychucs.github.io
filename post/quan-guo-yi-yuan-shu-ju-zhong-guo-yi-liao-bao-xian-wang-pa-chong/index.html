<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>全国医院数据-中国医疗保险网爬虫 | Andy Blog</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://andychucs.github.io/favicon.ico?v=1702196225608">
<link rel="stylesheet" href="https://andychucs.github.io/styles/main.css">


  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />
  

  


<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="先上项目地址
格式说明
输出格式为csv，表头为：医院名称,省份,城市,医院等级,擅长病症,医院地址,医院电话,医院邮箱,医院网站。
网站解析
网址的page参数是页数，k1到k3分别是省份、等级、重点科室。k4不知道是干什么的，还有一个t..." />
    <meta name="keywords" content="Python" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://andychucs.github.io">
        <img src="https://andychucs.github.io/images/avatar.png?v=1702196225608" class="site-logo">
        <h1 class="site-title">Andy Blog</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
          <a class="social-link" href="https://github.com/andychucs/" target="_blank">
            <i class="fab fa-github"></i>
          </a>
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      少即是多
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://andychucs.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">全国医院数据-中国医疗保险网爬虫</h2>
            <div class="post-date">2020-05-07</div>
            
              <div class="feature-container" style="background-image: url('https://andychucs.github.io/post-images/quan-guo-yi-yuan-shu-ju-zhong-guo-yi-liao-bao-xian-wang-pa-chong.png')">
              </div>
            
            <div class="post-content" v-pre>
              <p>先上<a href="https://github.com/AndyZhuAZ/hospital-crawler-CN">项目地址</a></p>
<h2 id="格式说明">格式说明</h2>
<p>输出格式为csv，表头为：医院名称,省份,城市,医院等级,擅长病症,医院地址,医院电话,医院邮箱,医院网站。</p>
<h2 id="网站解析">网站解析</h2>
<p>网址的page参数是页数，k1到k3分别是省份、等级、重点科室。k4不知道是干什么的，还有一个title参数用来搜索。我要爬取全部医院所以只需要遍历爬取全部页数的网页即可。<br>
https://www.zgylbx.com/index.php?m=content&amp;c=index&amp;a=lists&amp;catid=106&amp;page=1&amp;k1=&amp;k2=&amp;k3=&amp;k4=<br>
网页结构如图，医院列表装在&lt;table&gt;标签里，第零行是表头，之后的奇数行是基本信息，偶数行是医院地址,医院电话,医院邮箱,医院网站。<br>
<img src="https://andychucs.github.io/post-images/1588826502675.png" alt="" loading="lazy"></p>
<h2 id="代码说明">代码说明</h2>
<p>打开csv文件，writerows的参数是每一行的数据，列表嵌套结构，输入crawler函数返回的数据。</p>
<pre><code class="language-python">if __name__ == '__main__':
    url, headers = init()
    with open('hospital.csv', 'a') as f:
        write = csv.writer(f)
        write.writerows(crawler(url, headers))
</code></pre>
<p>crawler函数先设置表头，然后遍历全部页面，将解析成list的数据添加到rows，最后返回rows。</p>
<pre><code class="language-python">def crawler(u, h):
    rows = [[&quot;医院名称&quot;, '省份', '城市', &quot;医院等级&quot;, '擅长病症', '医院地址', '医院电话', '医院邮箱', '医院网站']]
    for i in range(1, 1530):
        r = requests.get(str(u) + str(i) + &quot;&amp;k1=0&amp;k2=0&amp;k3=0&amp;k4=&quot;, headers=h, timeout=20)
        print('url:'+str(u) + str(i) + &quot;&amp;k1=0&amp;k2=0&amp;k3=0&amp;k4=&quot;)
        soup = BeautifulSoup(r.text, &quot;html.parser&quot;)
        message = soup.find_all('tr')
        rows.extend(get_rows(message))
    return rows
</code></pre>
<p>get_rows函数将每一页的数据解析成一个list，从索引1开始遍历，设置一个flag确定当前行的类型，医院详细信息是写在一个标签里用br标签隔开的，所以手动分割一下。</p>
<pre><code class="language-python">def get_rows(msg):
    row_list = []
    row = []
    sub_row = False
    for line in msg[1:]:
        data = line.find_all('td')
        if not sub_row:
            prov_city = data[1].text.strip().split('-')
            row = [
                data[0].text,
                prov_city[0],
                prov_city[1],
                data[2].text,
                data[3].text
            ]
            sub_row = True
        else:
            data = str(data[0]).split('&lt;br/&gt;')
            add = data[0].strip().split('医院地址:')[-1]
            tel = data[1].strip().split('医院电话:')[-1]
            mail = data[2].strip().split('医院邮箱:')[-1]
            site = data[3].strip().split('医院网站:')[-1][:-5]
            row.extend([add, tel, mail, site])
            row_list.append(row)
            sub_row = False
    return row_list
</code></pre>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://andychucs.github.io/tag/HvoZXTUF_/" class="tag">
                    Python
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://andychucs.github.io/post/xiang-python-yi-yang-shi-yong-dartyi-lie-biao-sheng-cheng-list-comprehension/">
                  <h3 class="post-title">
                    像Python一样使用Dart（一）：列表生成 List comprehension
                  </h3>
                </a>
              </div>
            

            
              
                <div id="gitalk-container" data-aos="fade-in"></div>
              

              
            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>


  <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  <script>
    hljs.initHighlightingOnLoad()
  </script>




  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>

      var gitalk = new Gitalk({
        clientID: '097d7b64037dc9cfc0c6',
        clientSecret: 'be9557ddef753969b8d9c01c48b51dfc34508a95',
        repo: 'andychucs.github.io',
        owner: 'andychucs',
        admin: ['andychucs'],
        id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')

    </script>
  

  




  </body>
</html>
